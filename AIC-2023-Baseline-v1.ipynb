{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fcc581b",
   "metadata": {
    "id": "5fcc581b"
   },
   "source": [
    "# Hội thi Thử thách Trí tuệ Nhân tạo Thành phố Hồ Chí Minh 2024\n",
    "\n",
    "## Hướng dẫn truy vấn dữ liệu thị giác dùng fiftyone\n",
    "\n",
    "Đây là hướng dẫn dùng cho các đội tham dự AI Challenge 2024. Hướng dẫn này nhằm mục đích giới thiệu cho các đội một phương pháp cơ bản để truy vấn dữ liệu dựa trên thông tin BTC cung cấp và giới thiệu công cụ fiftyone để hỗ trợ đội thi đánh giá kết quả.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0880900",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a576d0",
   "metadata": {
    "id": "f5a576d0"
   },
   "outputs": [],
   "source": [
    "# ! pip install fiftyone==0.24.1\n",
    "# ! pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6771581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch\n",
    "# ! pip install ftfy regex tqdm\n",
    "# ! pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139bb46a",
   "metadata": {},
   "source": [
    "## Define library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d4489",
   "metadata": {
    "id": "357d4489"
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import json \n",
    "import os\n",
    "import torch\n",
    "import open_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7ba43",
   "metadata": {
    "id": "36b7ba43"
   },
   "source": [
    "Load dữ liệu keyframe từ thư mục chứa keyframe. Trong hướng dẫn này tất cả các file Keyframes_L*.zip được giải nén vào thư mục `D:\\AIC\\Keyframes`. Mỗi ảnh và thông tin đi kèm sau này sẽ được lưu trữ trong một `Sample`. Tất cả các `Sample` được lưu trong `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e072688",
   "metadata": {
    "id": "9e072688"
   },
   "outputs": [],
   "source": [
    "dataset = fo.Dataset.from_images_dir('/home/nguyenhoangphuc-22521129/AIC/Keyframes_L01/keyframes', name=None, tags=None, recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89e71c",
   "metadata": {
    "id": "9b89e71c"
   },
   "source": [
    "Sau khi dữ liệu đã load lên xong. Bạn có thể truy cập vào đường vào ứng dụng web của fiftyone từ [http://localhost:5151](http://localhost:5151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be11b8",
   "metadata": {
    "id": "58be11b8"
   },
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34567d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/nguyenhoangphuc-22521129/AIC/Keyframes_L01/keyframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ce744",
   "metadata": {
    "id": "078ce744"
   },
   "source": [
    "## Hoặc chạy cell này để mở tab cho ứng dụng web fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0d9ce",
   "metadata": {
    "id": "bce0d9ce"
   },
   "outputs": [],
   "source": [
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28298924",
   "metadata": {
    "id": "28298924"
   },
   "source": [
    "## Trích xuất thêm thông tin tên của video và frameid\n",
    "Thông tin `video` và `frameid` sẽ được lấy từ tên của tập tin keyframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e6918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee02ad",
   "metadata": {
    "id": "a8ee02ad"
   },
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    _, sample['video'], sample['frameid'] = sample['filepath'][:-4].rsplit('/', 2)\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309a34f",
   "metadata": {
    "id": "4309a34f"
   },
   "source": [
    "## Thêm thông tin kết quả của object detection.\n",
    "\n",
    "Bước này có thể tốn của bạn nhiều thời gian để đọc hết tất cả các dữ liệu về object detection. Bạn có thể bỏ qua cell này và chạy cell này sau nếu muốn thử thêm các thông tin về vector CLIP embedding trước."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c4395",
   "metadata": {
    "id": "ad1c4395"
   },
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    object_path = f\"/home/nguyenhoangphuc-22521129/AIC/HCMAI22_MiniBatch1/Objects/{sample['video']}/{sample['frameid']}.json\"\n",
    "    with open(object_path) as jsonfile:\n",
    "        det_data = json.load(jsonfile)\n",
    "    detections = []\n",
    "    for cls, box, score in zip(det_data['detection_class_entities'], det_data['detection_boxes'], det_data['detection_scores']):\n",
    "        # Convert to [top-left-x, top-left-y, width, height]\n",
    "        boxf = [float(box[1]), float(box[0]), float(box[3]) - float(box[1]), float(box[2]) - float(box[0])]\n",
    "        scoref = float(score)\n",
    "\n",
    "        # Only add objects with confidence > 0.4\n",
    "        if scoref > 0.4:\n",
    "            detections.append(\n",
    "                fo.Detection(\n",
    "                    label=cls,\n",
    "                    bounding_box= boxf,\n",
    "                    confidence=float(score)\n",
    "                )\n",
    "            )\n",
    "    sample[\"object_faster_rcnn\"] = fo.Detections(detections=detections)\n",
    "    sample.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287dbb4",
   "metadata": {
    "id": "e287dbb4"
   },
   "source": [
    "## Thêm thông tin CLIP embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5d9ca",
   "metadata": {
    "id": "58d5d9ca"
   },
   "outputs": [],
   "source": [
    "all_keyframe = glob('/home/nguyenhoangphuc-22521129/AIC/Keyframes_L01/keyframes/*/*.jpg')\n",
    "video_keyframe_dict = {}\n",
    "all_video = glob('/home/nguyenhoangphuc-22521129/AIC/Keyframes_L01/keyframes/*')\n",
    "all_video = [v.rsplit('/',1)[-1] for v in all_video]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb927629",
   "metadata": {
    "id": "cb927629"
   },
   "source": [
    "Tạo dictionary `video_keyframe_dict` với `video_keyframe_dict[video]` thông tin danh sách `keyframe` của `video`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33da133",
   "metadata": {
    "id": "f33da133"
   },
   "outputs": [],
   "source": [
    "for kf in all_keyframe:\n",
    "    _, vid, kf = kf[:-4].rsplit('/',2)\n",
    "    if vid not in video_keyframe_dict.keys():\n",
    "        video_keyframe_dict[vid] = [kf]\n",
    "    else:\n",
    "        video_keyframe_dict[vid].append(kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faefe0bf",
   "metadata": {
    "id": "faefe0bf"
   },
   "source": [
    "Do thông tin vector CLIP embedding được cung cấp được lưu theo từng video nhầm mục đích tối ưu thời gian đọc dữ liệu. Cần sort lại danh sách `keyframe` của từng `video` để đảm bảo thứ tự đọc đúng với vector embedding được cung cấp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0fad7a",
   "metadata": {
    "id": "4b0fad7a"
   },
   "outputs": [],
   "source": [
    "for k,v in video_keyframe_dict.items():\n",
    "    video_keyframe_dict[k] = sorted(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99d121",
   "metadata": {
    "id": "9d99d121"
   },
   "source": [
    "Tạo dictionary `embedding_dict` với `embedding_dict[video][keyframe]` lưu thông tin vector CLIP embedding của `keyframe` trong `video` tương ứng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d94d7b",
   "metadata": {
    "id": "a5d94d7b"
   },
   "outputs": [],
   "source": [
    "embedding_dict = {}\n",
    "for v in all_video:\n",
    "    clip_path = f'/home/nguyenhoangphuc-22521129/AIC/clip-features-vit-b32-sample/clip-features-vit-b32-sample/clip-features/{v}.npy'\n",
    "    a = np.load(clip_path)\n",
    "    embedding_dict[v] = {}\n",
    "    for i,k in enumerate(video_keyframe_dict[v]):\n",
    "        embedding_dict[v][k] = a[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0432e",
   "metadata": {
    "id": "5ea0432e"
   },
   "source": [
    "Tạo danh sách `clip_embedding` ứng với danh sách `sample` trong `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad16b5c",
   "metadata": {
    "id": "1ad16b5c"
   },
   "outputs": [],
   "source": [
    "clip_embeddings = []\n",
    "for sample in dataset:\n",
    "    clip_embedding = embedding_dict[sample['video']][sample['frameid']]\n",
    "    sample['clip_embedding'] = clip_embedding\n",
    "    sample.save()\n",
    "    clip_embeddings.append(clip_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33389802-2683-4ff7-a514-6ba2f42a18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ddf000",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c76abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_and_preprocess = open_clip.create_model_and_transforms(\"ViT-B-16\", pretrained=\"openai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19016acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_and_preprocess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = model_and_preprocess[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_resolution = preprocess.transforms[0].size[0]  # Kích thước đầu vào\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_search = \"A female is drawing a landscape picture\"\n",
    "text_tokens = open_clip.tokenize([text_search])\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_tokens).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9585535",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    a = sample['clip_embedding']\n",
    "    query_similarity = (text_features @ a.reshape(1,512).T).cpu().numpy().item()\n",
    "    sample['text_query_similarity'] = query_similarity\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09971ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4ee51",
   "metadata": {},
   "source": [
    "## Tạo chỉ mục Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a643b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = clip_embeddings[0].shape[0]  # Kích thước vector\n",
    "index = faiss.IndexFlatL2(d)  # Chỉ mục Flat với khoảng cách L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5824886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm các embedding vào chỉ mục\n",
    "index.add(np.array(clip_embeddings).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử bạn có một embedding truy vấn\n",
    "query_embedding = np.random.random((1, d)).astype('float32')  # Thay bằng embedding thực tế"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tìm kiếm k vector gần nhất\n",
    "k = 5  # Số lượng kết quả muốn tìm\n",
    "distances, indices = index.search(query_embedding, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In ra kết quả\n",
    "print(\"Khoảng cách đến các vector gần nhất:\", distances)\n",
    "print(\"Chỉ số của các vector gần nhất:\", indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c1aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c0002",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d2feb",
   "metadata": {
    "id": "655d2feb"
   },
   "outputs": [],
   "source": [
    "fob.compute_similarity(\n",
    "    dataset,\n",
    "    model=\"clip-vit-base32-torch\",      # store model's name for future use\n",
    "    embeddings=clip_embeddings,          # precomputed image embeddings\n",
    "    brain_key=\"new_img_sim\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99223338",
   "metadata": {
    "id": "99223338"
   },
   "source": [
    "## Từ đây các bạn có thể thử các tính năng search, filter trên ứng dụng fiftyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0706f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46605386",
   "metadata": {
    "id": "46605386"
   },
   "outputs": [],
   "source": [
    "# Bạn cần phải cài version umap-learn hỗ trợ.\n",
    "fob.compute_visualization(\n",
    "    dataset,\n",
    "    embeddings=clip_embeddings,\n",
    "    brain_key=\"img_viz\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381972d8",
   "metadata": {
    "id": "381972d8"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
